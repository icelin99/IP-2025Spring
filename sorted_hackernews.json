[
  {
    "by": "meetpateltech",
    "descendants": 156,
    "id": 43334644,
    "kids": [
      43338229,
      43337745,
      43338329,
      43335371,
      43335200,
      43335475,
      43335706,
      43335954,
      43337359,
      43335704,
      43335622,
      43340549,
      43335798,
      43335599,
      43339760,
      43350829,
      43337995,
      43341468,
      43337829,
      43335780,
      43337528,
      43336387,
      43335767,
      43356812,
      43337511,
      43336251,
      43337980,
      43342847,
      43337104,
      43346695,
      43339032,
      43337135,
      43334697,
      43337696,
      43338256,
      43338874,
      43335281,
      43338599
    ],
    "score": 387,
    "time": 1741712697,
    "title": "New tools for building agents",
    "type": "story",
    "url": "https://openai.com/index/new-tools-for-building-agents/",
    "similarity": 0.03577987373912811
  },
  {
    "by": "todsacerdoti",
    "descendants": 19,
    "id": 43356039,
    "kids": [
      43357399,
      43356329,
      43356246,
      43357059,
      43362088,
      43364539,
      43357125,
      43358959,
      43356512
    ],
    "score": 100,
    "time": 1741890747,
    "title": "Xata Agent: AI agent expert in PostgreSQL",
    "type": "story",
    "url": "https://github.com/xataio/agent",
    "similarity": 0.034341155453386334
  },
  {
    "by": "noddybear",
    "descendants": 209,
    "id": 43331582,
    "kids": [
      43333045,
      43334576,
      43338731,
      43335404,
      43334618,
      43342548,
      43332539,
      43334233,
      43335980,
      43331679,
      43335216,
      43332121,
      43331931,
      43332931,
      43332331,
      43334194,
      43331920,
      43334839,
      43332245,
      43332346,
      43331980,
      43334329,
      43331962,
      43337129,
      43343680,
      43334620,
      43346300,
      43335590,
      43331881,
      43331903,
      43336510,
      43331994,
      43332479,
      43332218,
      43331782,
      43336487,
      43332962,
      43331833,
      43337878,
      43332022,
      43335537,
      43335768,
      43331894,
      43332084,
      43334138,
      43333312,
      43332483,
      43333333,
      43341652
    ],
    "score": 747,
    "text": "I&#x27;m Jack, and I&#x27;m excited to share a project that has channeled my Factorio addiction recently: the Factorio Learning Environment (FLE).<p>FLE is an open-source framework for developing and evaluating LLM agents in Factorio. It provides a controlled environment where AI models can attempt complex automation, resource management, and optimisation tasks in a grounded world with meaningful constraints.<p>A critical advantage of Factorio as a benchmark is its unbounded nature. Unlike many evals that are quickly saturated by newer models, Factorio&#x27;s geometric complexity scaling means it won&#x27;t be &quot;solved&quot; in the next 6 months (or possibly even years). This allows us to meaningfully compare models by the order-of-magnitude of resources they can produce - creating a benchmark with longevity.<p>The project began 18 months ago after years of playing Factorio, recognising its potential as an AI research testbed. A few months ago, our team (myself, Akbir, and Mart) came together to create a benchmark that tests agent capabilities in spatial reasoning and long-term planning.<p>Two technical innovations drove this project forward: First, we discovered that piping Lua into the Factorio console over TCP enables running (almost) arbitrary code without directly modding the game. Second, we developed a first-class Python API that wraps these Lua programs to provide a clean, type-hinted interface for AI agents to interact with Factorio through familiar programming paradigms.<p>Agents interact with FLE through a REPL pattern:\n1. They observe the world (seeing the output of their last action)\n2. Generate Python code to perform their next action\n3. Receive detailed feedback (including exceptions and stdout)<p>We provide two main evaluation settings:\n- Lab-play: 24 structured tasks with fixed resources\n- Open-play: An unbounded task of building the largest possible factory on a procedurally generated map<p>We found that while LLMs show promising short-horizon skills, they struggle with spatial reasoning in constrained environments. They can discover basic automation strategies (like electric-powered drilling) but fail to achieve more complex automation (like electronic circuit manufacturing). Claude Sonnet 3.5 is currently the best model (by a significant margin).<p>The code is available at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;JackHopkins&#x2F;factorio-learning-environment\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;JackHopkins&#x2F;factorio-learning-environment</a>.<p>You&#x27;ll need:\n- Factorio (version 1.1.110)\n- Docker\n- Python 3.10+<p>The README contains detailed installation instructions and examples of how to run evaluations with different LLM agents.<p>We would love to hear your thoughts and see what others can do with this framework!",
    "time": 1741694522,
    "title": "Show HN: Factorio Learning Environment – Agents Build Factories",
    "type": "story",
    "url": "https://jackhopkins.github.io/factorio-learning-environment/",
    "similarity": 0.033530073608606
  },
  {
    "by": "StatsAreFun",
    "descendants": 15,
    "id": 43348434,
    "kids": [
      43376577,
      43376878,
      43376561,
      43377971,
      43378010,
      43383442
    ],
    "score": 43,
    "time": 1741819083,
    "title": "Strengthening AI Agent Hijacking Evaluations",
    "type": "story",
    "url": "https://www.nist.gov/news-events/news/2025/01/technical-blog-strengthening-ai-agent-hijacking-evaluations",
    "similarity": 0.03191822124685666
  },
  {
    "by": "ksec",
    "descendants": 168,
    "id": 43331847,
    "kids": [
      43372532,
      43369540,
      43372975,
      43369821,
      43369702,
      43369601,
      43370106,
      43370088,
      43375143,
      43370387,
      43371464,
      43374588,
      43376025,
      43370928,
      43369987,
      43373348,
      43373720,
      43376820,
      43370566,
      43372213,
      43370179,
      43372005,
      43370520,
      43370792,
      43376576,
      43374569,
      43372800,
      43369914,
      43371078,
      43370145,
      43384650,
      43373466,
      43370924,
      43370816,
      43370591,
      43370156,
      43374330
    ],
    "score": 636,
    "time": 1741696855,
    "title": "RubyLLM: A delightful Ruby way to work with AI",
    "type": "story",
    "url": "https://github.com/crmne/ruby_llm",
    "similarity": 0.03177901519893616
  },
  {
    "by": "thinkingemote",
    "descendants": 46,
    "id": 43380617,
    "kids": [
      43381037,
      43381079,
      43381842,
      43381664,
      43382903,
      43380888,
      43383244,
      43381554,
      43381377,
      43381515
    ],
    "score": 124,
    "time": 1742145813,
    "title": "\"Wait, not like that\": Free and open access in the age of generative AI",
    "type": "story",
    "url": "https://www.citationneeded.news/free-and-open-access-in-the-age-of-generative-ai/",
    "similarity": 0.0317758468460038
  },
  {
    "by": "boznz",
    "descendants": 164,
    "id": 43312652,
    "kids": [
      43314906,
      43320850,
      43314655,
      43314796,
      43314958,
      43320610,
      43320375,
      43316319,
      43316939,
      43314519,
      43315040,
      43315094,
      43316033,
      43324313,
      43314813,
      43322104,
      43314347,
      43322288,
      43316110,
      43314305,
      43322200,
      43328968,
      43315469,
      43320546,
      43322778,
      43314511,
      43329701,
      43315042,
      43314395,
      43314393,
      43315364,
      43321373,
      43330549,
      43314507,
      43314820,
      43320497
    ],
    "score": 305,
    "time": 1741547921,
    "title": "With AI you need to think bigger",
    "type": "story",
    "url": "https://rodyne.com/?p=1828",
    "similarity": 0.030923250310301246
  },
  {
    "by": "achintms",
    "descendants": 7,
    "id": 43362535,
    "kids": [
      43374502,
      43370406,
      43367731,
      43366655
    ],
    "score": 23,
    "text": "Hey HN, after years building some of the core AI and NLU systems in Google Search, we decided to leave and build outside. Our goal was to put the advanced ML and DS techniques we’ve been using in the hands of all software engineers, so that everyone can build AI and Search apps at the same level of performance and sophistication as the big labs.<p>This was a hard technical challenge but we were very inspired by the MVC architecture for Web development. The intuition there was that when a data model changes, its view would get auto-updated. We built a similar architecture for AI. On one side is a scoring system, which encapsulates in a set of metrics what’s good about the AI application. On the other side is a set of optimizers that “compile” against this scorer - prompt optimization, data filtering, synthetic data generation, supervised learning, RL, etc. The scoring system can be calibrated using developer, user or rater feedback, and once it’s updated, all the optimizers get recompiled against it.<p>The result is a setup that makes it easy to incrementally improve the quality of your AI in a tight feedback loop: You update your scorers, they auto-update your optimizers, your app gets better, you see that improvement in interpretable scores, and then you repeat, progressing from simpler to more advanced optimizers and from off-the-shelf to calibrated scorers.<p>We would love your feedback on this approach. <a href=\"https:&#x2F;&#x2F;build.withpi.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;build.withpi.ai</a> has a set of playgrounds to help you quickly build a scorer and multiple optimizers. No sign in required. <a href=\"https:&#x2F;&#x2F;code.withpi.ai\" rel=\"nofollow\">https:&#x2F;&#x2F;code.withpi.ai</a> has the API reference and Notebook links. Finally, we have a Loom demo [1].<p><i>More technical details</i><p><i>Scorers:</i> Our scoring system has three key differences from the common LLM-as-a-judge pattern.<p>First, rather than a single label or metric from an LLM judge, our scoring system is represented as a tunable tree of metrics, with 20+ dimensions which get combined into a final (non-linear) weighted score. The tree structure makes scores easily interpretable (just look at the breakdown by dimension), extensible (just add&#x2F;remove a dimension), and adjustable (just re-tune the weights). Training the scoring system with labeled&#x2F;preference data adjusts the weights. You can automate this process with user feedback signals, resulting in a tight feedback loop.<p>Second, our scoring system handles natural language dimensions (great for free-form, qualitative questions requiring NLU) alongside quantitative dimensions (like computations over dates or doc length, which can be provided in Python) in the same tree. When calibrating with your labeled or preference data, the scorer learns how to balance these.<p>Third, for natural language scoring, we use specialized smaller encoder models rather than autoregressive models. Encoders are a natural fit for scoring as they are faster and cheaper to run, easier to fine-tune, and more suitable architecturally (bi-directional attention with regression or classification head) than similar sized decoder models. For example, we can score 20+ dimensions in sub-100ms, making it possible to use scoring everywhere from evaluation to agent orchestration to reward modeling.<p><i>Optimizers:</i> We took the most salient ML techniques and reformulated them as optimizers against our scoring system e.g. for DSPy, the scoring system acts as its validator. For GRPO, the scoring system acts as its reward model. We’re keen to hear the community’s feedback on which techniques to add next.<p>Overall stack: Playgrounds next.js and Vercel. AI: Runpod and GCP for training GPUs, TRL for training algos, ModernBert &amp; Llama as base models. GCP and Azure for 4o and Anthropic calls.<p>We’d love your feedback and perspectives: Our team will be around to answer questions and discuss. If there’s a lot of interest, happy to host a live session!<p>- Achint, co-founder of Pi Labs<p>[1] <a href=\"http:&#x2F;&#x2F;loom.com&#x2F;share&#x2F;c09a1fda8cdf4003a5664fa9cfbf7804\" rel=\"nofollow\">http:&#x2F;&#x2F;loom.com&#x2F;share&#x2F;c09a1fda8cdf4003a5664fa9cfbf7804</a>",
    "time": 1741959438,
    "title": "Show HN: Pi Labs – AI scoring and optimization tools for software engineers",
    "type": "story",
    "url": "https://build.withpi.ai/dashboard",
    "similarity": 0.029825386370755047
  },
  {
    "by": "pcfwik",
    "descendants": 86,
    "id": 43323860,
    "kids": [
      43325833,
      43323913,
      43324788,
      43325846,
      43332515,
      43333604,
      43324950
    ],
    "score": 108,
    "time": 1741630977,
    "title": "STEPS Toward the Reinvention of Programming (2012) [pdf]",
    "type": "story",
    "url": "https://tinlizzie.org/VPRIPapers/tr2012001_steps.pdf",
    "similarity": 0.02959079893034969
  },
  {
    "by": "pseudolus",
    "descendants": 39,
    "id": 43327506,
    "kids": [
      43364811,
      43364624,
      43362949,
      43363076
    ],
    "score": 53,
    "time": 1741650105,
    "title": "Liu Jiakun Receives the 2025 Pritzker Architecture Prize",
    "type": "story",
    "url": "https://www.pritzkerprize.com/laureates/liu-jiakun",
    "similarity": 0.029500488966463314
  }
]